---
title: "Cartel detection"
author: "Margherita Atzei, Sebastian Kimm Friedberg, Oscar Krumlinde, Filip Mellgren"
date: '2020-03-11'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(viridis)
library(patchwork)
df <- rio::import("Data_Buehler_Wallimann.xlsx")
```
# First behavoural screen
## Set parameters
```{r}
# Use 0.7 as decision criteria
dc <- 0.7
```

## Create summary statistics
These statistics are based on those in the ML paper.

```{r, include = FALSE}
# Create statistics used for behavioral screening 
# Note, formula (6) for altrd MIGHT be wrong in the paper. Implemented with wrong sign.
df %>% arrange(project, bid) %>% group_by(project) %>% 
   mutate(
     pairwise_diff = bid - lag(bid, order_by=bid)) %>%
  summarise(
    sdev_bid = sqrt(var(bid)), 
    mean_bid = mean(bid), 
    no_bids = n(),
    win_bid = min(bid),
    date = first(anonymiseddate), 
    contract_type = first(contract_type), 
    procedure = first(procedure),
    diff = min(bid[bid!=min(bid)]) - min(bid),
    rel_diff = diff / min(bid),
    kurt = sum( ((bid - mean(bid)) / sdev_bid)^4),
    skew = sum( ((bid - mean(bid)) / sdev_bid)^3),
    rd = diff/sqrt(var((bid[bid!=min(bid)]))),
    altrd = (no_bids - 1) * diff / (sum(pairwise_diff, na.rm = TRUE) - diff),
    altrd2 = (no_bids - 1) * diff / (min(bid[bid!=min(bid)]) - max(bid)) # Equivalent magnitude (but takes reversed sign into account)
    ) %>%
  mutate(
    CV = sdev_bid / mean_bid, 
    kurt = kurt * no_bids*(no_bids+1) / ((no_bids - 1)*(no_bids - 2)* (no_bids - 3)),
    kurt = kurt - 3 * (no_bids - 1)^3 / ((no_bids - 2) * no_bids - 3),
    skew = skew * no_bids / ( (no_bids - 1) * (no_bids -2) )
    ) -> df_agg
```

```{r cleaning}
# TODO: find a plan for how to deal with the drop in observations.
# Lost observations due to missings: 4434 - 3882 = 552
df_agg %>% select(project, CV, altrd, no_bids) %>% filter_all(any_vars(!is.infinite(df_agg$altrd))) %>% na.omit() -> df_agg_filtered

df_agg <- left_join(df_agg_filtered, df_agg)

# clean away extreme values of altrd
df_agg <- df_agg %>% filter(altrd < 10)
```

## Apply model
In the ML paper, the authors fit a logistic regression and give the coefficients. We simply use these coefficients to generate predictions. Important, this implicitly assumes our data come from the same distribution as the data found in the ML paper. This assuption must be discussed when we present our evidence.

Also,  note that this is only an exploratory anb rough draft so far and that there are some things to do before the actual graphs can be produced. 

```{r model}
# Alternatice way: force coefficients: https://tolstoy.newcastle.edu.au/R/e2/help/07/08/24294.html
m3 <- c(1.02, -0.49, 0.92, 0.09)
m4 <- c(1.51, -0.47, 0.95, 0)
names(m3) <- c("CONST", "CV", "ALTRD", "NoBIDS")
names(m4) <- names(m3)
model <- m3

df_agg %>%
  mutate(
    probability_collusion = 1 / (1 + exp(-(model["CONST"] + model["CV"] * CV + 
                                             model["ALTRD"] * altrd2 +
                                             model["NoBIDS"] * no_bids))),
    exp_harm = probability_collusion * win_bid # make more precise
    ) -> df_agg
```
Because of the possible mistake in the paper, we're unsure shether to use altrd or altrd2.


```{r}
df_agg %>% ggplot(aes(x=probability_collusion, y=log(win_bid), z = exp_harm, color=exp_harm)) + 
  theme_minimal() +
  geom_point(size = 2, alpha = 0.3) + scale_colour_continuous(type='viridis') +
  labs(x = "Probability of collusion", 
       y = "Winning bid, log", 
       color = "Expected harm",
       title = "Projects by probability of collusion and value")
```
## Create confusion matrix

```{r}
# Data from ML paper fig 3 and Oscars eye balling skills
TP <- c(1, 0.91, 0.85, 0.77, 0.64, 0.38)
TN <- c(0, 0.69, 0.78, 0.86, 0.91, 0.97)
FP <- 1 - TP
FN <- 1 - TN
dc_vec <- c(0, 0.5, 0.6, 0.7, 0.8, 0.9)
certainty_info <- cbind(dc_vec, TP, TN, FP, FN) %>% as_tibble()

# TODO: ok to have varying decision criteria?
df_agg <- df_agg %>% mutate(floor_p_col = floor(probability_collusion * 10)/10,
                           floor_p_col = if_else(floor_p_col < 0.5, 0, floor_p_col))

df_agg <- left_join(df_agg, certainty_info, by = c("floor_p_col" = "dc_vec"))

df_agg <- df_agg %>% mutate(precision = TP / (TP + FP),
                  recall = TP / (TP + FN))
```

```{r confusion_matrix}
dc_ix <- 4
num_pos <- df_agg %>% filter(probability_collusion >= dc) %>% nrow()
num_neg <- df_agg %>% filter(probability_collusion < dc) %>% nrow()
conf_actual <- c("Cartel", "Fair")
conf_pred <- c("Cartel", "Fair")
conf_mat <- expand.grid(X=conf_pred, Y=conf_actual)
conf_mat$conf_data <- c(TP[[dc_ix]] * num_pos , FN[[dc_ix]] * num_pos, 
                        FP[[dc_ix]] * num_neg, TN[[dc_ix]]*num_neg)
conf_mat$colors <- c(0,1,1,0)

conf_mat %>% ggplot(aes(conf_mat$X, conf_mat$Y)) +
  geom_tile(aes(fill = colors)) + 
  labs(title = "Model accuracy",
       y = "Actual cartel status", x = "Predicted cartel status",
       subtitle  = "Figure shows expected number of tenders in each category \nTotal number of tenders classified: 3882") + 
  theme_minimal() +
  geom_text(aes(label = round(conf_data, 2)),size = 8, color = "white") +
 # scale_fill_distiller(palette = "RdYlGn", values = c(-0.4, 1.4)) +
  scale_fill_gradient2(low = "skyblue", high = "coral", mid = "white", 
   midpoint = 0.5, limit = c(0,1.2), space = "Lab", 
    name="")
```
## Plot densities of occurences.

```{r}
df_classified <- df_agg %>% na.omit() %>% 
  mutate(pos = if_else(probability_collusion > dc, 1, 0),
         contr_type = contract_type,
         pos2 = pos) %>%
  unite(col = "dens_cat", c(pos2, contr_type ))


plot_dist <- function(data, contract){
  data %>% filter(contract_type == contract) %>%
  ggplot(aes(x = date, color = as.factor(pos), fill = as.factor(pos))) +
  geom_density(alpha = 0.6, show.legend = FALSE, trim = FALSE, adjust = 0.75) +
    scale_color_manual(values=c("skyblue", "coral")) +
    scale_fill_manual(values=c("skyblue", "coral")) +
    theme_minimal() + labs(x = "")
}

dist_cat1 <- plot_dist(df_classified, 1)
dist_cat2 <- plot_dist(df_classified, 2)
dist_cat3 <- plot_dist(df_classified, 3)

dist_cat1 / dist_cat2 / dist_cat3 + 
  labs(caption = "Red indicates predicted status is cartel", x = "Date")

kstest_contract <- function(df, type){
  x <- df %>% filter(pos == 1) %>% filter(contract_type == type) %>% select(date)
  y <- df %>% filter(pos == 0) %>% filter(contract_type == type) %>% select(date)
  x <- x$date
  y <- y$date
  ks.test(x, y)
}

# Test whether events deemed fair respecitve collusive occur at different points in time
kstest_contract(df_classified, 1)
kstest_contract(df_classified, 2)
kstest_contract(df_classified, 3)
```


# Clustering algorithm
The idea is to cluster our observations into two categories which we then match with predictions made using the ML algorithm. If there is a strong correlation between the two, there is evidence of two clear groups and we might be able to discern a pattern.
```{r}
df_cluster <- df_agg  %>% 
  select(probability_collusion, contract_type, CV, altrd, kurt, skew,  procedure) %>% mutate(procedure = if_else(procedure == "Offenes", 1, 0))

cluster_type <- function(df, type){
  df <- df %>% filter(contract_type %in% type) %>% na.omit()
  df2 <- df %>% select(-c(probability_collusion)) %>% 
  scale() %>% as_tibble()

  clusters <- kmeans(df2[,2:length(df2)], 2, nstart = 25)
  df2$cluster <- as.factor(clusters$cluster)
  
  df2 <- df2 %>% mutate(cluster1 = if_else(cluster == "1", 1, 0))
  df$cluster <- df2$cluster
  print(cor(as.integer(df$cluster), df$probability_collusion))
  return(df)
}

get_pc <- function(df, type){
  df <- cluster_type(df, type)
  df_pca <- df %>% select(-c(probability_collusion, contract_type, cluster))
  pca_stats <- prcomp(x = df_pca)
  pca_stats$scores <- as.matrix(df_pca) %*% pca_stats$rotation
  PCs_stats <- pca_stats$scores[, 1:3]
  df$PCA1 <- pca_stats$scores[, 1]
  df$PCA2 <- pca_stats$scores[, 3]
  return(df)
}


df_pca1 <- get_pc(df_cluster, c(1,2,3))
df_pca2 <- get_pc(df_cluster, 2)
df_pca3 <- get_pc(df_cluster, 3)

df_pca3 %>% ggplot(aes(x = PCA1, y =probability_collusion, color =  cluster)) + geom_point()
df_pca1 %>% ggplot(aes(x = PCA1, y =PCA2, color =  probability_collusion > dc)) + geom_point()

```


```{r filter_data}
# Filter data based on the first behavioural screen
# TODO: probably not so smart to filter away those identified as not collusive after all
df_agg_ml <- df_agg# %>% filter(probability_collusion > dc) 

```



# Second behavioural screen Time series for structural breaks
Afer meeting. Do a structural break which provides further evidence. Improtant to invclude as further evidence.

Idea is to identify break points in one metric and then use a Chow test to test for structural breaks in another important statistic.

```{r create_sb_data}
df_sb <- right_join(df, df_agg_ml, by = c("project" = "project")) %>% as_tibble()

df_sb <- df_sb %>% select(-c("contract_type.x", "procedure.x")) %>% 
  rename(contract_type = contract_type.y, procedure = procedure.y)

# Form variables at the contract type level
df_sb %>% group_by(contract_type) %>% 
  mutate(mean_CV = mean(CV),
         CV_stand = (CV - mean_CV)/mean_CV,
         mean_altrd = mean(altrd),
         altrd_stand = (altrd - mean_altrd) / mean_altrd) %>% 
  ungroup() %>% na.omit() -> df_sb

# Group data by project 
df_sb %>% group_by(project, anonymiseddate) %>% 
  summarise(CV_stand = first(CV_stand), 
            contract_type = first(contract_type),
            probability_collusion = first(probability_collusion),
            altrd = first(altrd),
            rd = first(rd)) %>% 
  ungroup() -> df_sb
```


```{r structural_breaks}
# builds upon section 6.1.2 in Bucirossi's handbook

struc_break <- function(df, type){
  df %>% filter(contract_type == type) %>%
  ggplot(aes(x = anonymiseddate, y = CV_stand, color = as.factor(contract_type)), alpha = 1) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  scale_colour_brewer(palette = "Accent") +
  scale_fill_brewer(palette = "Accent") +
  labs(title = "Changes in collusive measure over time") +
  geom_point(aes(color = rd > 1))
}

struc_break(df_sb, 1)
struc_break(df_sb, 2)
struc_break(df_sb, 3)

```

```{r get_break_points}
loess_max <- function(y,x){
  max <- max(predict(loess(y~x),  data = c(y, x)))
             }
loess_argmax <- function(y,x){
  argmax <- which.max(predict(loess(y~x),  data = c(y, x)))
  argmax <- x[argmax]
             }
max_cv <- c()
min_cv <- c()
argmax_cv <- c()
argmin_cv <- c()

# Get break points for each category type
for(ix in 1:3){
  df_tmp <- df_sb %>% filter(contract_type == ix)
  Y_tmp <- df_tmp$CV_stand
  X_tmp <- df_tmp$anonymiseddate
  max_cv[ix] <- loess_max(Y_tmp, X_tmp)
  min_cv[ix] <- loess_max(-Y_tmp, X_tmp)
  argmax_cv[ix] <- loess_argmax(Y_tmp, X_tmp)
  argmin_cv[ix] <- loess_argmax(-Y_tmp, X_tmp)
}
```

```{r plot_bp}
df_sb %>%
  ggplot(aes(x = anonymiseddate, y = altrd, color = as.factor(contract_type)), alpha = 1) +
  geom_vline(aes(xintercept = argmin_cv[3]), 
             linetype="dotted", size=1.5, color = "orange", alpha = 0.8)+
  geom_vline(aes(xintercept = argmax_cv[2]), 
             linetype="dotted", size=1.5, color = "purple", alpha = 0.5) +
  geom_vline(aes(xintercept = argmin_cv[1]), 
             linetype="dotted", size=1.5, color = "darkgreen", alpha = 0.5) +
geom_vline(aes(xintercept = argmax_cv[1]), 
             linetype="dotted", size=1.5, color = "darkgreen", alpha = 0.5) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  scale_colour_brewer(palette = "Accent") +
  scale_fill_brewer(palette = "Accent") +
  labs(title = "Structural break?",
       subtitle = "lines indicate structural break candidate values")
```


```{r}
df_sb %>% group_by(project, anonymiseddate) %>% 
  summarise(altrd_stand = first(altrd_stand), contract_type = first(contract_type)) %>% 
  ungroup() %>%
  ggplot(aes(x = anonymiseddate, y = altrd_stand, color = as.factor(contract_type)), alpha = 1) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  scale_colour_brewer(palette = "Accent") +
  scale_fill_brewer(palette = "Accent") +
  labs(title = "Changes in collusive measure over time")

df_sb %>% group_by(project, anonymiseddate) %>% 
  summarise(probability_collusion = first(probability_collusion), contract_type = first(contract_type)) %>% 
  ungroup() %>%
  ggplot(aes(x = anonymiseddate, y = probability_collusion, color = as.factor(contract_type)), alpha = 1) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  scale_colour_brewer(palette = "Accent") +
  scale_fill_brewer(palette = "Accent") +
  labs(title = "Changes in collusive measure over time")
```


Find markers from OECD summary, look at CV, when it is low, there is an increased likelihood of a cartel. 

Also, Difference between the two lowest bids divided by the standard deviation of the "cover bids" (all bids that did not win)".

Descriptive statistics, by type:
Procedure type (var, mean, bids)

