---
title: "Cartel detection"
author: "Margherita Atzei, Sebastian Kimm Friedberg, Oscar Krumlinde, Filip Mellgren"
date: '2020-03-11'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(viridis)
df <- rio::import("Data_Buehler_Wallimann.xlsx")
```

# Create summary statistics
These statistics are based on those in the ML paper.

```{r, include = FALSE}
# Create statistics used for behavioral screening 
# Note, formula (6) for altrd MIGHT be wrong in the paper. Implemented with wrong sign.
df %>% arrange(project, bid) %>% group_by(project) %>% 
   mutate(
     pairwise_diff = bid - lag(bid, order_by=bid)) %>%
  summarise(
    sdev_bid = sqrt(var(bid)), 
    mean_bid = mean(bid), 
    no_bids = n(),
    win_bid = min(bid),
    date = first(anonymiseddate), 
    contract_type = first(contract_type), 
    procedure = first(procedure),
    diff = min(bid[bid!=min(bid)]) - min(bid),
    rel_diff = diff / min(bid),
    kurt = sum( ((bid - mean(bid)) / sdev_bid)^4),
    skew = sum( ((bid - mean(bid)) / sdev_bid)^3),
    rd = diff/sqrt(var((bid[bid!=min(bid)]))),
    altrd = (no_bids - 1) * diff / (sum(pairwise_diff, na.rm = TRUE) - diff),
    altrd2 = (no_bids - 1) * diff / (min(bid[bid!=min(bid)]) - max(bid)) # Equivalent magnitude (but takes reversed sign into account)
    ) %>%
  mutate(
    CV = sdev_bid / mean_bid, 
    kurt = kurt * no_bids*(no_bids+1) / ((no_bids - 1)*(no_bids - 2)* (no_bids - 3)),
    kurt = kurt - 3 * (no_bids - 1)^3 / ((no_bids - 2) * no_bids - 3),
    skew = skew * no_bids / ( (no_bids - 1) * (no_bids -2) )
    ) -> df_agg
```

```{r cleaning}
# TODO: find a plan for how to deal with the drop in observations.
# Lost observations due to missings: 4434 - 3882 = 552
df_agg %>% select(project, CV, altrd, no_bids) %>% filter_all(any_vars(!is.infinite(df_agg$altrd))) %>% na.omit() -> df_agg_filtered

df_agg <- left_join(df_agg_filtered, df_agg)
```

# Apply model
In the ML paper, the authors fit a logistic regression and give the coefficients. We simply use these coefficients to generate predictions. Important, this implicitly assumes our data come from the same distribution as the data found in the ML paper. This assuption must be discussed when we present our evidence.

Also,  note that this is only an exploratory anb rough draft so far and that there are some things to do before the actual graphs can be produced. 

```{r model}
# Alternatice way: force coefficients: https://tolstoy.newcastle.edu.au/R/e2/help/07/08/24294.html
m3 <- c(1.02, -0.49, 0.92, 0.09)
m4 <- c(1.51, -0.47, 0.95, 0)
names(m3) <- c("CONST", "CV", "ALTRD", "NoBIDS")
names(m4) <- names(m3)
model <- m3

df_agg %>%
  mutate(
    probability_collusion = 1 / (1 + exp(-(model["CONST"] + model["CV"] * CV + 
                                             model["ALTRD"] * altrd2 +
                                             model["NoBIDS"] * no_bids))),
    exp_harm = probability_collusion * win_bid # make more precise
    ) -> df_agg
```
Because of the possible mistake in the paper, we're unsure shether to use altrd or altrd2.


```{r}
df_agg %>% ggplot(aes(x=probability_collusion, y=log(win_bid), z = exp_harm, color=exp_harm)) + 
  theme_minimal() +
  geom_point(size = 2, alpha = 0.3) + scale_colour_continuous(type='viridis') +
  labs(x = "Probability of collusion", 
       y = "Winning bid, log", 
       color = "Expected harm",
       title = "Projects by probability of collusion and value")
```
```{r}
# Data from ML paper fig 3 and Oscars eye balling skills
TP <- c(1, 0.91, 0.85, 0.77, 0.64, 0.38)
TN <- c(0, 0.69, 0.78, 0.86, 0.91, 0.97)
FP <- 1 - TP
FN <- 1 - TN
dc <- c(0, 0.5, 0.6, 0.7, 0.8, 0.9)
certainty_info <- cbind(dc, TP, TN, FP, FN) %>% as_tibble()

# TODO: ok to have varying decision criteria?
df_agg <- df_agg %>% mutate(floor_p_col = floor(probability_collusion * 10)/10,
                           floor_p_col = if_else(floor_p_col < 0.5, 0, floor_p_col))

df_agg <- left_join(df_agg, certainty_info, by = c("floor_p_col" = "dc"))

df_agg <- df_agg %>% mutate(precision = TP / (TP + FP),
                  recall = TP / (TP + FN))
```

```{r confusion_matrix}
# Use 0.7 as decision criteria
dc <- 0.7
dc_ix <- 4
num_pos <- df_agg %>% filter(probability_collusion >= dc) %>% nrow()
num_neg <- df_agg %>% filter(probability_collusion < dc) %>% nrow()
conf_actual <- c("Cartel", "Fair")
conf_pred <- c("Cartel", "Fair")
conf_mat <- expand.grid(X=conf_pred, Y=conf_actual)
conf_mat$conf_data <- c(TP[[dc_ix]] * num_pos , FN[[dc_ix]] * num_pos, 
                        FP[[dc_ix]] * num_neg, TN[[dc_ix]]*num_neg)
conf_mat$colors <- c(0,1,1,0)

conf_mat %>% ggplot(aes(conf_mat$X, conf_mat$Y)) +
  geom_tile(aes(fill = colors)) + 
  labs(title = "Model accuracy",
       y = "Actual cartel status", x = "Predicted cartel status",
       subtitle  = "Figure shows expected number of tenders in each category \nTotal number of tenders classified: 3882") + 
  theme_minimal() +
  geom_text(aes(label = round(conf_data, 2)),size = 8, color = "white") +
 # scale_fill_distiller(palette = "RdYlGn", values = c(-0.4, 1.4)) +
  scale_fill_gradient2(low = "skyblue", high = "#FA8072", mid = "white", 
   midpoint = 0.5, limit = c(0,1.2), space = "Lab", 
    name="")
```


# Time series for structural breaks

Afer meeting. Do a structural break which provides further evidence. Improtant to invclude as further evidence.

Idea is to identify break points in one metric and then use a Chow test to test for structural breaks in another important statistic.

```{r structural_breaks}
# builds upon section 6.1.2 in Bucirossi's handbook
# TODO: NA is currently white
df %>% ggplot(aes(x = anonymiseddate, y = log(bid), color = as.factor(contract_type))) +
  geom_smooth(aes(fill =as.factor(contract_type))) +
  theme_minimal() + scale_colour_viridis(discrete = TRUE) +
  scale_fill_viridis(discrete = TRUE)
```

```{r prob_collusion_time}
df_agg %>% 
  ggplot(aes(x = date, y = probability_collusion, color = as.factor(contract_type))) +
  geom_smooth(aes(fill =as.factor(contract_type))) +
  theme_minimal() + scale_colour_viridis(discrete = TRUE) +
  scale_fill_viridis(discrete = TRUE)
```
```{r}
df_agg %>% filter(rd < 2000) %>% 
  ggplot(aes(x = date, y = rd, color = as.factor(contract_type))) +
  geom_smooth(aes(fill =as.factor(contract_type))) +
  theme_minimal() + scale_colour_viridis(discrete = TRUE) +
  scale_fill_viridis(discrete = TRUE)
```

Find markers from OECD summary, look at CV, when it is low, there is an increased likelihood of a cartel. 

Also, Difference between the two lowest bids divided by the standard deviation of the "cover bids" (all bids that did not win)".

Descriptive statistics, by type:
Procedure type (var, mean, bids)

