---
title: "Cartel detection"
author: "Margherita Atzei, Sebastian Kimm Friedberg, Oscar Krumlinde, Filip Mellgren"
date: '2020-03-11'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(viridis)
library(patchwork)
df <- rio::import("Data_Buehler_Wallimann.xlsx")
```
# First behavoural screen
## Set parameters
```{r}
dc <- 0.7
```

## Create summary statistics
These statistics are based on those in the ML paper.

```{r, include = FALSE}
# Create statistics used for behavioral screening 
# Note, formula (6) for altrd MIGHT be wrong in the paper. Implemented with wrong sign.
df %>% arrange(project, bid) %>% group_by(project) %>% 
   mutate(
     pairwise_diff = bid - lag(bid, order_by=bid)) %>%
  summarise(
    mean_bid = mean(bid), 
    no_bids = n(),
    sdev_bid = sd(bid), # NOTE: sd() defaults t0 denom n-1, want n.
    win_bid = min(bid),
    date = first(anonymiseddate), 
    year = first(anonymisedyear), 
    contract_type = first(contract_type), 
    procedure = first(procedure),
    diff = min(bid[bid!=min(bid)]) - min(bid),
    rel_diff = diff / min(bid),
    kurt = sum( ((bid - mean(bid)) / sdev_bid)^4),
    skew = sum( ((bid - mean(bid)) / sdev_bid)^3),
    rd = diff/sqrt(var((bid[bid!=min(bid)]))),
    altrd = (no_bids - 1) * diff / (sum(pairwise_diff, na.rm = TRUE) - diff),
    altrd2 = (no_bids - 1) * diff / (min(bid[bid!=min(bid)]) - max(bid)) # Equivalent magnitude (but takes reversed sign into account)
    ) %>%
  mutate(
    CV = (sdev_bid / mean_bid) * sqrt((no_bids-1)/(no_bids)), 
    kurt = kurt * no_bids*(no_bids+1) / ((no_bids - 1)*(no_bids - 2)* (no_bids - 3)),
    kurt = kurt - 3 * (no_bids - 1)^3 / ((no_bids - 2) * no_bids - 3),
    skew = skew * no_bids / ( (no_bids - 1) * (no_bids -2) )
    ) -> df_agg
```

```{r manual_check}
# Manual check that altrd calculation is correct
# Project 3
bid_3 <- c(141967.15, 144485.40, 132293.50)
b1 <- min(bid_3)
b2 <- min(bid_3[bid_3!=b1])
b3 <- max(bid_3)

altrd_manual <- (b2 - b1) / ( (b2 - b3) / 2)
# compare with: -7.682835
altrd_manual - -7.682835

```

```{r cleaning}
# TODO: find a plan for how to deal with the drop in observations.
# NOTE that man y observations dissapear here
# Lost observations due to missings: 4434 - 3882 = 552
df_agg %>% select(project, CV, no_bids, contract_type) %>% filter_all(any_vars(!is.infinite(df_agg$altrd))) %>% na.omit() -> df_agg_filtered

df_agg <- left_join(df_agg_filtered, df_agg)

# clean away extreme values of altrd
df_agg <- df_agg %>% filter(altrd < 10)
```

## Apply model
In the ML paper, the authors fit a logistic regression and give the coefficients. We simply use these coefficients to generate predictions. Important, this implicitly assumes our data come from the same distribution as the data found in the ML paper. This assuption must be discussed when we present our evidence.

Also,  note that this is only an exploratory anb rough draft so far and that there are some things to do before the actual graphs can be produced. 

```{r model}
# Alternatice way: force coefficients: https://tolstoy.newcastle.edu.au/R/e2/help/07/08/24294.html
m3 <- c(1.02, -0.49, 0.92, 0.09)
m4 <- c(1.51, -0.47, 0.95, 0)
names(m3) <- c("CONST", "CV", "ALTRD", "NoBIDS")
names(m4) <- names(m3)
model <- m4

df_agg %>%
  mutate(
    probability_collusion = 1 / (1 + exp(-(model["CONST"] + model["CV"] * CV + 
                                             model["ALTRD"] * altrd2 +
                                             model["NoBIDS"] * no_bids))),
    exp_harm = probability_collusion * win_bid # make more precise
    ) -> df_agg
```
Because of the possible mistake in the paper, we're unsure shether to use altrd or altrd2.


```{r}
df_agg %>% ggplot(aes(x=probability_collusion, y=log(win_bid), z = exp_harm, color=exp_harm)) + 
  theme_minimal() +
  geom_point(size = 2, alpha = 0.3) + scale_colour_continuous(type='viridis') +
  labs(x = "Probability of collusion", 
       y = "Winning bid, log", 
       color = "Expected harm",
       title = "Projects by probability of collusion and value")
```
## Create confusion matrix

```{r}
# Data from ML paper fig 3 and Oscars eye balling skills
TP <- c(1, 0.91, 0.85, 0.77, 0.64, 0.38)
TN <- c(0, 0.69, 0.78, 0.86, 0.91, 0.97)
FP <- 1 - TN
FN <- 1 - TP
dc_vec <- c(0, 0.5, 0.6, 0.7, 0.8, 0.9)
certainty_info <- cbind(dc_vec, TP, TN, FP, FN) %>% as_tibble()

df_agg <- df_agg %>% mutate(pred_cartel = if_else(probability_collusion > dc, 1, 0))
```

```{r confusion_matrix}
dc_ix <- which(dc_vec == dc)
num_cartel_pred <- df_agg %>% filter(probability_collusion >= dc) %>% nrow()
num_fair_pred <- df_agg %>% filter(probability_collusion < dc) %>% nrow()

# Prepare data
conf_actual <- c("Cartel", "Fair")
conf_pred <- c("Cartel", "Fair")
conf_mat <- expand.grid(X=conf_pred, Y=conf_actual)
conf_mat$conf_data <- c(TP[[dc_ix]] , FN[[dc_ix]], 
                        FP[[dc_ix]], TN[[dc_ix]])
conf_mat$colors <- c(0,1,1,0)

# Plot the confusion matrix
conf_mat %>% ggplot(aes(conf_mat$X, conf_mat$Y)) +
  geom_tile(aes(fill = colors)) + 
  labs(title = "Model accuracy",
       y = "Actual cartel status", x = "Predicted cartel status",
       subtitle  = "Figure shows expected number of tenders in each category \nTotal number of tenders classified: 3685") + 
  theme_minimal() +
  geom_text(aes(label = round(conf_data, 2)),size = 8, color = "white") +
 # scale_fill_distiller(palette = "RdYlGn", values = c(-0.4, 1.4)) +
  scale_fill_gradient2(low = "skyblue", high = "coral", mid = "white", 
   midpoint = 0.5, limit = c(0,1.2), space = "Lab", 
    name="") +
  theme(legend.position = "none")
ggsave("images/confmat.png")
```
## Plot densities of occurences.

```{r}
df_classified <- df_agg %>% na.omit() %>% 
  mutate(pos = if_else(probability_collusion > dc, 1, 0),
         contr_type = contract_type,
         pos2 = pos) %>%
  unite(col = "dens_cat", c(pos2, contr_type ))

plot_dist <- function(data, contract, category_name){
  # TODO: at what date does year 1 begin?
  data %>% filter(contract_type %in% contract) %>%
  ggplot(aes(x = date, color = as.factor(pos), fill = as.factor(pos))) +
  geom_histogram(alpha = 0.6, show.legend = FALSE,  binwidth = 365, position = "fill") +
    geom_rug(data = data %>% filter(pos == 1, contract_type == contract), size = 2) +
    scale_color_manual(values=c("skyblue", "coral")) +
    scale_fill_manual(values=c("skyblue", "coral")) +
    theme_minimal() + labs(x = "") +
    theme(legend.position = "None") +
    labs(title = category_name, y = "Fraction")
}

dist_cat1 <- plot_dist(df_classified, 1, "Strassenbau")
dist_cat2 <- plot_dist(df_classified, 2, "Strassen und Tiefbau")
dist_cat3 <- plot_dist(df_classified, 3, "Tiefbau")

dist_cat1 / dist_cat2 / dist_cat3 + 
  labs(caption = "Red indicates predicted status is cartel", x = "Date")
ggsave("images/densities.png")

kstest_contract <- function(df, type){
  # Tests whether data can be said to come from a uniform distribution in the 
  # interval of the data
  # TODO: should we change interval to 0 and whatever max we have?
  x <- df %>% filter(pos == 1) %>% filter(contract_type == type) %>% select(date)
  y <- df %>% filter(pos == 0) %>% filter(contract_type == type) %>% select(date)
  x <- x$date
  y <- y$date
  low <- min(min(x), min(y))
  high <- max(max(x), max(y))
  ks.test(x, "punif",low, high)
}

# Test whether events deemed fair respecitve collusive occur at different points in time
kstest_contract(df_classified, 1)
kstest_contract(df_classified, 2)
kstest_contract(df_classified, 3)
```

```{r}
df_agg %>% select(project, year, contract_type, CV) %>% #na.omit() %>% 
  group_by(year, contract_type) %>% 
  summarise(avg_cv = mean(CV)) %>%
  ggplot(aes(x = year, y = avg_cv, color = as.factor(contract_type))) + 
  geom_line() +
  theme_minimal() +
  scale_color_discrete(name = "Contract type", labels = c("Strassenbau", "Strassen und Tiefbau", "Tiefbau")) +
  labs(y = "Yearly Mean Coeff. of Variation", x = "Year", title = "Cartels are more likely marked by low values")

ggsave("images/CV_year.png")
```

# Plot CV over time
```{r}
plot_cv <- function(type){
  df_agg %>% filter(contract_type == type) %>% 
    ggplot(aes(x = date, y = CV)) +
    theme_minimal() +
    geom_point()
}
str_cv <- plot_cv(1)
mix_cv <- plot_cv(2)
tief_cv <- plot_cv(3)
str_cv/mix_cv/tief_cv

ggsave("images/CV_scatter.png")

```


# Second behavioural screen Time series for structural breaks
Afer meeting. Do a structural break which provides further evidence. Improtant to invclude as further evidence.

Idea is to identify break points in one metric and then use a Chow test to test for structural breaks in another important statistic.

```{r get_break_points}
loess_max <- function(y,x){
  max <- max(predict(loess(y~x),  data = c(y, x)))
             }
loess_argmax <- function(y,x){
  argmax <- which.max(predict(loess(y~x),  data = c(y, x)))
  argmax <- x[argmax]
             }
max_cv <- c()
min_cv <- c()
argmax_cv <- c()
argmin_cv <- c()

# Get break points for each category type
for(ix in 1:3){
  df_tmp <- df_agg %>% filter(contract_type == ix)
  Y_tmp <- df_tmp$CV
  X_tmp <- df_tmp$date
  max_cv[ix] <- loess_max(Y_tmp, X_tmp)
  min_cv[ix] <- loess_max(-Y_tmp, X_tmp)
  argmax_cv[ix] <- loess_argmax(Y_tmp, X_tmp)
  argmin_cv[ix] <- loess_argmax(-Y_tmp, X_tmp)
}
```

```{r structural_breaks}
# builds upon section 6.1.2 in Bucirossi's handbook

struc_break <- function(df){
  df %>%
  ggplot(aes(x = date, y = CV, color = as.factor(contract_type)), alpha = 1) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  labs(title = "title")+
    geom_vline(aes(xintercept = argmin_cv[1]), 
             linetype="dotted", size=1.5, color = "red", alpha = 0.5) +
        geom_vline(aes(xintercept = argmin_cv[2]), 
             linetype="dotted", size=1.5, color = "green", alpha = 0.5) +
        geom_vline(aes(xintercept = argmin_cv[3]), 
             linetype="dotted", size=1.5, color = "blue", alpha = 0.5)
}

CV_time <- struc_break(df_agg)
```

```{r plot_bp}
prob_col_time <- df_agg %>%
  ggplot(aes(x = date, y = altrd2, color = as.factor(contract_type)), alpha = 1) +
geom_vline(aes(xintercept = argmin_cv[1]), 
             linetype="dotted", size=1.5, color = "red", alpha = 0.5) +
  geom_vline(aes(xintercept = argmin_cv[2]), 
             linetype="dotted", size=1.5, color = "green", alpha = 0.5) +
  geom_vline(aes(xintercept = argmin_cv[3]), 
             linetype="dotted", size=1.5, color = "blue", alpha = 0.5) +
  geom_smooth(aes(fill = as.factor(contract_type)), alpha = 0.4) +
  theme_minimal() + 
  labs(title = "Structural break?",
       subtitle = "lines indicate structural break candidate values")
```


```{r}
CV_time
prob_col_time
```


```{r Chow}
# TODO: Shouldnt probability of collusion DECREASE when CV increase?
library(strucchange)
chow_test <- function(df, type, bp){
  df <- df %>% filter(contract_type == type)
  sc <- sctest(df$probability_collusion ~ df$date, type = "Chow", point = bp)
  return(sc)
}

# Break point for series one
type <- 1
bpoint <- which(df_agg$date == argmin_cv[type])
chow_test(df_agg, type, bpoint[1])

type <- 1
bpoint <- which(df_agg$date == 1751)
chow_test(df_agg, type, bpoint[1])

type <- 3
bpoint <- which(df_agg$date == argmin_cv[type])
chow_test(df_agg, type, bpoint[1])



```

Find markers from OECD summary, look at CV, when it is low, there is an increased likelihood of a cartel. 

Also, Difference between the two lowest bids divided by the standard deviation of the "cover bids" (all bids that did not win)".

Descriptive statistics, by type:
Procedure type (var, mean, bids)